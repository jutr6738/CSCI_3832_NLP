{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Sentiment Analysis with Naïve Bayes\n",
    "#### CSCI 3832 Natural Language Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lemmas and inflected forms, hyponyms/hypernyms, the distributional hypothesis\n",
    "2. Tokenization, vocabularies, and feature extraction for a Naive Bayes model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia Troni\n",
    "### julia.troni@colorado.edu or jutr6738@colorado.edu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Free Response Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1: Write down the lemmas of the following inflected forms:**\n",
    "1. walked\n",
    "2. taught\n",
    "3. best\n",
    "4. are\n",
    "5. running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "1. walk\n",
    "2. teach\n",
    "3. good\n",
    "4. be\n",
    "5. run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2: Write down 3 hyponyms of the following words:**\n",
    "1. dog\n",
    "2. food\n",
    "3. profession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "1. dog- golden retriever, lab, border collie\n",
    "2. food - peanut butter, banana, tofu\n",
    "3. profession- teacher, chef, doctor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3: In your own words, describe:**\n",
    "1. The distributional hypothesis (see lecture on distributional semantics)\n",
    "2. How is the distributional hypothesis relvant to NLP systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "\n",
    "The distributional hypothesis states that words that occur in similar contexts tend to have similar meanings. \n",
    "This is relevant to NLP systems because it is the foundation for many techniques, such as word embeddings, which can then be used as input for many NLP applications such as language translation and text classification. Also,the distributional hypothesis can also be used to develop models of word meaning and similarity that can be used in tasks such as word sense disambiguation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Sentiment Analysis with Naive Bayes\n",
    "\n",
    "In this section, our goal is to classify a set of movie reviews as positive or negative. For our dataset, we'll use the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/). To get started, download the dataset from the link, and extract it to where your notebook is. Next, we'll load the data and look at a couple of examples. \n",
    "\n",
    "*Important: for any project which involves creating or training models, you can **only** do your exploratory data analysis on the training set. Looking at the test set in any way can invalidate your results!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive examples: 12500\n",
      "Number of negative examples: 12500\n",
      "\n",
      "\n",
      "Sample positive example: Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n",
      "\n",
      "\n",
      "Sample negative example: Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'aclImdb/'\n",
    "\n",
    "pos_train_dir = data_dir + 'train/pos/'\n",
    "neg_train_dir = data_dir + 'train/neg/'\n",
    "\n",
    "def read_folder(folder):\n",
    "    examples = []\n",
    "    for fname in os.listdir(folder):\n",
    "        with open(os.path.join(folder, fname), encoding='utf8') as f:\n",
    "            examples.append(f.readline().strip())\n",
    "    return examples\n",
    "\n",
    "pos_examples = read_folder(pos_train_dir)\n",
    "neg_examples = read_folder(neg_train_dir)\n",
    "\n",
    "print('Number of positive examples: {}\\nNumber of negative examples: {}\\n\\n'.format(len(pos_examples), len(neg_examples)))\n",
    "\n",
    "print('Sample positive example: {}\\n\\n'.format(pos_examples[0]))\n",
    "print('Sample negative example: {}'.format(neg_examples[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded the data, let's create our vocabulary. While we want our vocabulary to cover the whole training set, we'll keep them separate to see if there are any words which are frequently found in one or the other class -- these words might be informative features for classification! \n",
    "\n",
    "The simplest way to create a vocabulary is to split on spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "pos_words = []  # A list of all space separated tokens found across all positive examples. (Contains duplicates)\n",
    "neg_words = []\n",
    "\n",
    "pos_vocab = set()  # A list of *unique* separated tokens found in across all positive examples. (No duplicates)\n",
    "neg_vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Counts of total words (tokens)\n",
    "\n",
    "pos_words=[]  # A list of all space separated tokens found across all positive examples. (Contains duplicates)\n",
    "\n",
    "for pos in pos_examples:\n",
    "    strs=pos.split(' ')\n",
    "    for s in strs:\n",
    "        pos_words.append(s)\n",
    "\n",
    "neg_words = []\n",
    "for neg in neg_examples:\n",
    "    strs=neg.split(' ')\n",
    "    for s in strs:\n",
    "        neg_words.append(s)\n",
    "\n",
    "#counts of unique words (types)\n",
    "pos_vocab = set(pos_words)  # A list of *unique* separated TYPES found in across all positive examples. (No duplicates)\n",
    "neg_vocab = set(neg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2958696\n",
      "178873\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "print(len(pos_words))\n",
    "print(len(pos_vocab))\n",
    "\n",
    "assert len(pos_words) == 2958696\n",
    "assert len(pos_vocab) == 178873"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets calculate word frequencies for each class. (Hint: use the Python Counter class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "pos_frequencies = [] # A list of tuples of the form (word, count). \n",
    "                 # The list should be sorted in descending order, using the count of each tuple as the key\n",
    "\n",
    "neg_frequencies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "''' \n",
    "Your code here. For each class (positive/negative) calculate the frequency of each word and save it in pos_counter\n",
    "and neg_counter.\n",
    "\n",
    "Print the top 15 most common word for each class. \n",
    "\n",
    "'''\n",
    "\n",
    "pos_frequencies = Counter(pos_words).most_common() # A list of tuples of the form (word, count). \n",
    "                 # The list should be sorted in descending order, using the count of each tuple as the key\n",
    "\n",
    "neg_frequencies = Counter(neg_words).most_common() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert pos_frequencies[0] == ('the', 148413)\n",
    "assert neg_frequencies[0] == ('the', 138612)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 positive words [('the', 148413), ('and', 84270), ('a', 79427), ('of', 75341), ('to', 65209), ('is', 55358), ('in', 45794), ('that', 31941), ('I', 30927), ('it', 26987), ('this', 26021), ('/><br', 24617), ('as', 23930), ('with', 22031), ('was', 21308)]\n",
      "\n",
      "Top 15 negative words [('the', 138612), ('a', 75665), ('and', 68381), ('of', 67629), ('to', 67359), ('is', 47870), ('in', 39782), ('I', 35043), ('that', 32615), ('this', 31177), ('it', 27440), ('/><br', 26318), ('was', 25389), ('for', 20197), ('with', 19687)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Top 15 positive words\", pos_frequencies[0:15])\n",
    "print('')\n",
    "print(\"Top 15 negative words\", neg_frequencies[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the top 15 words for each class we see two problems:\n",
    "\n",
    "1. The words are essentially the same for each class, which doesn't give us any information on how to differentiate them.\n",
    "2. Look at the most frequent tokens. Are there any tokens which aren't words? Any situations where tokens with different surface forms but the same meaning could be repeated (and if so, how might we control for this?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer to 2 here*\n",
    "\n",
    "- Tokens that appear that are not words but still represent meaning: \n",
    "    - punctuation like   \"...\",   \"<br\",   \"br/>\",   \"/>\"   \n",
    "    - emoji representations such as   XD,   :p,   =],   O_O \n",
    "    - numbers \n",
    "\n",
    "\n",
    "- Tokens with different surface forms but the same meaning that are repeated: \n",
    "    - Uppercase vs. lowercase \n",
    "        - And vs. and\n",
    "        - OK vs. Ok vs. ok\n",
    "        - We can control for this by converting the list of words to all lowercase using .tolower()\n",
    "    - With vs. without punctuation and differences in spacing:\n",
    "        - and...funny vs.  and... vs. funny\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking at the most frequent words, let's instead look at the most frequent words which explicitly do not appear in the other class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Edie', 82), ('Gundam', 74), ('Antwone', 58), ('/>8/10', 47), ('/>7/10', 46), ('/>10/10', 45), ('Gunga', 44), ('Gypo', 44), ('Din', 43), ('Othello', 41), ('7/10.', 37), ('Blunt', 37), ('Yokai', 37), ('Tsui', 35), ('Blandings', 34), ('Goldsworthy', 32), ('/>9/10', 31), ('Gino', 31), ('Visconti', 30), ('Bernsen', 29), ('Taker', 29), ('Brashear', 29), ('Harilal', 29), ('Clutter', 28), (\"Goldsworthy's\", 27), ('\"Rob', 26), ('Dominick', 25), ('MJ', 25), ('/>7', 24), ('Rosenstrasse', 24), ('Sassy', 24), ('Flavia', 24), ('Ashraf', 23), ('Recommended.', 22), ('Brock', 22), ('vulnerability', 22), ('Sabu', 22), ('Korda', 22), ('Ahmad', 22), ('Stevenson', 22), ('Coop', 22), ('Riff', 22), ('flawless.', 21), ('aunts', 21), (\"Gilliam's\", 21), ('Solo', 21), ('Kells', 21), (\"Capote's\", 21), ('Cutter', 21), ('Blackie', 21)]\n",
      "\n",
      "\n",
      "[('/>4/10', 56), ('/>Avoid', 55), ('2/10', 49), ('*1/2', 45), ('unwatchable.', 43), ('/>3/10', 40), ('Thunderbirds', 40), ('Gamera', 39), ('steaming', 35), ('Wayans', 33), ('Slater', 31), ('drivel.', 30), ('Tashan', 29), ('Aztec', 29), ('/>1/10', 28), ('Sarne', 27), ('Kareena', 26), ('BTK', 26), ('Segal', 26), ('blah,', 26), ('Delia', 26), ('0/10', 25), ('neither.', 25), ('Gram', 25), ('(*1/2)', 24), ('croc', 24), ('Dahmer', 24), ('Darkman', 24), ('Rosanna', 23), ('Zenia', 23), ('tripe.', 22), ('awful!', 22), ('2/10.', 22), ('Kornbluth', 22), ('Saif', 21), ('incoherent,', 21), ('appallingly', 21), ('Shaq', 21), ('Welch', 21), ('Hackenstein', 21), ('/>2/10', 20), ('4/10.', 20), ('kibbutz', 20), ('Clay', 20), ('Morgana', 20), ('\"1\"', 19), ('crawling', 19), ('/>1', 19), ('awfulness', 19), ('Mraovich', 19)]\n"
     ]
    }
   ],
   "source": [
    "only_pos_words = [word for word in pos_words if word not in neg_vocab]\n",
    "only_neg_words = [word for word in neg_words if word not in pos_vocab]\n",
    "\n",
    "opw_counter = Counter(only_pos_words)\n",
    "onw_counter = Counter(only_neg_words)\n",
    "\n",
    "print(opw_counter.most_common()[:50])\n",
    "print('\\n')\n",
    "print(onw_counter.most_common()[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin to see some words we would expect to denote a negative review, but not so much for the positive reviews. Why might this be the case? What types of tokens are found in positive reviews but not in negative reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "\n",
    "The negative reivew words contain words such as \"unwachable\", \"appalling\", \"incoherent\" which are very indicative of negative sentiment. Positive review words contain far more proper nouns and names. This may be because positive reviews seem to give more of a description and summary of plot, rather than negative reviews are very to the point and explicit that the movie was bad. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of space separated vocab: 281137\n",
      "['unredeemable', 'lucid.)', 'CRYPT', 'Zumhofe', 'cry)...', 'MILD', 'style\",', 'Bonzai\"', 'answer?', 'stainless', 'disturbed,', 'intro.', 'Dorn,', 'France?', 'Golan,', 'comedy,,', 'contact?', 'donna', 'Rights-approved', 'thirdly...', '/>Later', 'psilcybe', ':C)', 'goofy,', 'shamelessly),', 'Andy', 'Killing', \"Stack's,\", \"Meighan's\", 'Arthurs', \"Shahadah's\", 'super-annoying.<br', 'scariest.', 'Speaksman', '\"Boy,', 'DVD-R', \"'adult'\", 'coot,\"', 'WALTER', 'lame-brain,', 'Vance', 'sun.Sheriff', 'Survives\",', \"night'.\", 'MAJOR', 'Capote', 'Condemned.),and', 'Tad', 'Doran,', 'Bellwood.<br']\n"
     ]
    }
   ],
   "source": [
    "# Lets now make our combined vocabulary\n",
    "space_vocab = list(pos_vocab.union(neg_vocab))\n",
    "print('Length of space separated vocab: {}'.format(len(space_vocab)))\n",
    "print(space_vocab[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at some words from our vocab, what issue do we find by only splitting on spaces?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "\n",
    "One large issue we have by splitting only on spaces is that our vocab includes punctuation, single letters, text breakers, names, proper nouns, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, rather than naively splitting on spaces, we can use tools which are informed about English grammar rules to create a cleaner tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', ',', 'such', 'as', '``', 'Teachers', \"''\", '.', 'My', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'Bromwell', 'High', \"'s\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '``', 'Teachers', \"''\", '.', 'The', 'scramble', 'to', 'survive', 'financially', ',', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', 'teachers', \"'\", 'pomp', ',', 'the', 'pettiness', 'of', 'the', 'whole', 'situation', ',', 'all', 'remind', 'me', 'of', 'the', 'schools', 'I', 'knew', 'and', 'their', 'students', '.', 'When', 'I', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school', ',', 'I', 'immediately', 'recalled', '.........', 'at', '..........', 'High', '.', 'A', 'classic', 'line', ':', 'INSPECTOR', ':', 'I', \"'m\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers', '.', 'STUDENT', ':', 'Welcome', 'to', 'Bromwell', 'High', '.', 'I', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'Bromwell', 'High', 'is', 'far', 'fetched', '.', 'What', 'a', 'pity', 'that', 'it', 'is', \"n't\", '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pos_examples_tokenized = [word_tokenize(ex) for ex in pos_examples]\n",
    "neg_examples_tokenized = [word_tokenize(ex) for ex in neg_examples]\n",
    "\n",
    "print(pos_examples_tokenized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first example we can see that things like apostrophes, periods, \"n'ts\" and ellipses are better handled.\n",
    "\n",
    "Let's begin defining features for our model. The simplest features are simply if a word exists or not -- however, this is will be very slow if we decide to use the whole vocabulary. Instead, let's create these features for the top 100 most common words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', ',', '.', 'and', 'a', 'of', 'to', 'is', '/', '>', '<', 'br', 'in', 'I', 'it', 'that', \"'s\", 'this', 'was', 'The', 'as', 'with', 'movie', 'for', 'film', ')', '(', 'but', \"n't\", \"''\", '``', 'on', 'you', 'are', 'not', 'have', 'his', 'be', 'he', '!', 'one', 'at', 'by', 'all', 'an', 'who', 'they', 'from', 'like', 'It', 'her', 'so', 'or', 'about', 'has', 'just', 'out', '?', 'do', 'This', 'some', 'good', 'more', 'very', 'would', 'what', 'there', 'up', 'can', 'which', 'when', 'time', 'she', 'had', 'if', 'only', 'really', 'story', 'were', 'their', 'even', 'see', 'no', 'my', 'me', 'does', \"'\", 'did', ':', '-', 'than', '...', 'much', 'been', 'could', 'into', 'get', 'will', 'we', 'other']\n"
     ]
    }
   ],
   "source": [
    "all_tokenized_words = [word for ex in pos_examples_tokenized for word in ex] + \\\n",
    "    [word for ex in neg_examples_tokenized for word in ex]\n",
    "\n",
    "atw_counter = Counter(all_tokenized_words)\n",
    "top100 = [tup[0] for tup in atw_counter.most_common(100)] # A list of the top 100 most frequent word\n",
    "\n",
    "print(top100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "####################\n",
    "##   Here I further clean the vocab to improve my model\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Function to remove all stop words from the given word list such as \"the\", \"a\", \"is\", etc. \n",
    "def RemoveStopWords(word_list):\n",
    "    filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_nostop = [RemoveStopWords(ex) for ex in pos_examples_tokenized[0:300]]##only using 300 since otherwise the computer overloads\n",
    "neg_nostop = [RemoveStopWords(ex) for ex in neg_examples_tokenized[0:300]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove the proper nouns from a word list \n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "def RemoveProperNouns(word_list):\n",
    "    tagged = nltk.tag.pos_tag(word_list)\n",
    "    edited = [word for word,tag in tagged if tag != 'NNP' and tag != 'NNPS']\n",
    "    return edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_clean = [RemoveProperNouns(ex) for ex in pos_nostop]\n",
    "neg_clean = [RemoveProperNouns(ex) for ex in neg_nostop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'br', 'I', \"'s\", 'movie', 'The', ')', '(', 'film', \"n't\", \"''\", '``', 'one', '!', '<', 'like', 'It', '>', '?', 'good', 'This', 'story', 'would', 'time', 'even', '...', 'see', 'bad', 'much', ':', 'really', \"'\", 'get', 'first', '-', 'great', 'people', 'made', 'could', 'think', 'movies', 'seen', 'characters', 'well', 'make', 'ever', 'never', 'many', 'But', 'two', 'films', 'way', 'watch', '&', 'character', 'also', 'better', 'acting', 'scenes', 'plot', 'scene', 'In', 'go', 'little', ';', 'And', 'best', 'show', \"'ve\", 'actors', 'He', 'love', 'action', 'end', 'life', 'say', 'man', 'still', 'know', 'If', 'years', 'back', 'director', 'A', 'There', 'though', 'something', 'real', 'actually', 'got', 'pretty', 'watching', 'nothing', \"'m\", 'series', 'done', '--', 'give', 'thing']\n"
     ]
    }
   ],
   "source": [
    "all_clean_words = [word for ex in pos_clean for word in ex] + \\\n",
    "    [word for ex in neg_clean for word in ex]\n",
    "\n",
    "all_clean_counter = Counter(all_clean_words)\n",
    "top100clean = [tup[0] for tup in all_clean_counter.most_common(100)] # A list of the top 100 most frequent cleaned word\n",
    "\n",
    "print(top100clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following block to define your own features for the NB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I did the cleaning for this added feature above \n",
    "def top100_clean_word_features(example): # 100 features, 1 for each word in the top 100 most frequent cleaned words\n",
    "    #note cleaned words has no stop words and no nouns\n",
    "    return {word : 1 if word in example else 0 for word in top100clean}\n",
    "\n",
    "\n",
    "##list of words that I would consider have a positive sentiment \n",
    "pos_sentiment=[\"fantastic\", \"wonderful\", \"incredible\", \"recommended\"]\n",
    "def example_feature(example): #Delete or modify this \n",
    "    return {word : 1 if word in example else 0 for word in pos_sentiment}\n",
    "\n",
    "def create_feature_dictionary(example):\n",
    "    features = {}\n",
    "    for feat in [ top100_clean_word_features, example_feature]: #Once you've created your methods, and them to this list\n",
    "        features.update(feat(example))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined our features for our model, we can create our final dataset, which will consist of extracted features and the example label. \n",
    "\n",
    "We'll also create a *validation* split by taking 20% of the training dataset. Remember, we never use the test set to make modeling decisions (in this case, decisions about features). Experiment with multiple models that make use of different combinations of features. Measure their performance on the validation split to figure out which features are the most helpful (use the show_most_informative_features function). When you've found your final model, evaluate its performance on the held out data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "import random\n",
    "\n",
    "# Convert training examples to a set of features.\n",
    "train = [(create_feature_dictionary(ex), 0) for ex in neg_examples] + \\\n",
    "                [(create_feature_dictionary(ex), 1) for ex in pos_examples]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(train)\n",
    "\n",
    "split_percent = .2\n",
    "\n",
    "cutoff = int(split_percent * len(train))\n",
    "\n",
    "validation_set = train[:cutoff]\n",
    "training_set = train[cutoff:]\n",
    "\n",
    "model = NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7224\n",
      "Most Informative Features\n",
      "               wonderful = 1                   1 : 0      =      4.5 : 1.0\n",
      "               fantastic = 1                   1 : 0      =      4.1 : 1.0\n",
      "              incredible = 1                   1 : 0      =      3.1 : 1.0\n",
      "             recommended = 1                   1 : 0      =      3.0 : 1.0\n",
      "                     bad = 1                   0 : 1      =      2.9 : 1.0\n",
      "                 nothing = 1                   0 : 1      =      2.1 : 1.0\n",
      "                   great = 1                   1 : 0      =      2.0 : 1.0\n",
      "                    love = 1                   1 : 0      =      1.8 : 1.0\n",
      "                       ? = 1                   0 : 1      =      1.7 : 1.0\n",
      "                    best = 1                   1 : 0      =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.util import accuracy\n",
    "\n",
    "print('Validation accuracy: {}'.format(accuracy(model, validation_set)))\n",
    "model.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the sets of features you've considered, and note down their performance below. What is the final set of features you found?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "\n",
    "Since our goal is sentiment analysis, I wanted to evaluate the movies using words that actually indicat positive or negative. So I recleanedthe words to create a new feature. \n",
    "\n",
    "First, I removed all \"stop words\" such as “a”, “the”, “is”, “are”, etc. since these do not indicate any sentiment\n",
    "Then I removed proper nouns\n",
    "Lastly I took the top100 of that new set of clean words \n",
    "\n",
    "This brought the performance from ~61% to ~72%\n",
    "\n",
    "Then,I also devised a list of words that I would classify as \"positive sentiment\" and that brought the validation accuracy to ~73%. Obviously, this list is just a start and with more research I could certainly improve this \n",
    "\n",
    "\n",
    "While I technically only added 2 features, the extraction of stop words and nouns took a significant amount of work and research and improved the accuracy considerably more than other ideas I tried (such as length). I hope I am not deducted points simply because I only added 2 features. I always believe in quality over quantity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, test your model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Load and process test data\n",
    "pos_test_examples = read_folder(data_dir + 'test/pos/')\n",
    "neg_test_examples = read_folder(data_dir + 'test/neg/')\n",
    "\n",
    "test_set = [(create_feature_dictionary(ex), 0) for ex in neg_test_examples] + \\\n",
    "                [(create_feature_dictionary(ex), 1) for ex in pos_test_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.71948\n"
     ]
    }
   ],
   "source": [
    "print('Test set accuracy: {}'.format(accuracy(model, test_set)))\n",
    "\n",
    "# Note that we're looking at accuracy -- this is not always the most reliable metric and other choices like F1 might be more informative. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Self note: Total time spent on homework: 50+ hours. For next time- get debugging help/clarification earlier. \n",
    "#Ask sooner than later! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e681adf14836894860de42986132a2fbb5bf9e0a673e28b245b6aa439c639a4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
